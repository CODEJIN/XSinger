Sound:
    Hop_Size: 256
    N_Mel: 100
    Sample_Rate: 24000
    F0_Min: 65  # C2
    F0_Max: 2094    # C7

Tokens: 124
Notes: 128
Durations: 10000
Singers: 1
Languages: 1

Encoder:
    Size: 384
    Lyric_Encoder:
        Stack: 4
        Head: 2
        Dropout_Rate: 0.1
        Beta_Distribution_Concentration: 0.2
        FFN:
            Kernel_Size: 7
            Dropout_Rate: 0.1
    Melody_Encoder:
        Stack: 4
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 7
            Dropout_Rate: 0.1
    Phoneme_to_Note_Encoder:
        Stack: 2
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 7
            Dropout_Rate: 0.1
    Phoneme_to_Note_Cross_Encoder:
        Stack: 2
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 7
            Dropout_Rate: 0.1

F0_Predictor:
    Size: 128
    Scheduler: 'Uniform' # 'Cosmap'
    Kernel_Size: 3
    Stack: 10
    Dilation_Cycle: 4
    Use_CFG: true
    Use_OT: true
    Coarse_Bin: 256

Prior_Encoder:
    Stack: 8
    Kernel_Size: 5
    Projection_Kernel_Size: 3
    
# CFM:
#     Size: 512
#     Scheduler: 'Uniform' # 'Cosmap'
#     Transformer:
#         Stack: 6
#         Head: 2
#         Dropout_Rate: 0.1
#         FFN:
#             Kernel_Size: 3
#             Dropout_Rate: 0.1
#     Use_OT: true
#     Use_CFG: true


Token_Path: './Pattern/Token.yaml'
Mel_Info_Path: './Pattern/Mel_Info.yaml'
F0_Info_Path: './Pattern/F0_Info.yaml'
Singer_Info_Path: './Pattern/Singer_Info.yaml'
Genre_Info_Path: './Pattern/Genre_Info.yaml'
Language_Info_Path: './Pattern/Language_Info.yaml'
Train:
    Pattern_Cache: false
    Train_Pattern:
        Path: './Pattern/Train'
        Metadata_File: 'METADATA.PICKLE'
        Accumulated_Dataset_Epoch: 100 # This is to prevent slow down from torch.utils.data.DataLoader when the number of patterns is small.
        Augmentation_Ratio: 0.10
    Eval_Pattern:
        Path: './Pattern/Eval'
        Metadata_File: 'METADATA.PICKLE'
        Accumulated_Dataset_Epoch: 4   # When singer is 1, evaluation pattern is also 1. Because offset is selected randomly, this is meaningful.
    Num_Workers: 2
    Batch_Size: 16
    Pattern_Length:
        Min: 384
        Max: 768
    Num_Combination: 3
    Learning_Rate:
        Initial: 1.0e-4
        Decay: 0.999875
        Decay_Epoch: 1000
        Lambda:
            Cross_Attention: 10.0
            Optimal_Transport: 0.5
    ADAM:
        Beta1: 0.9
        Beta2: 0.999
        Epsilon: 1.0e-7
    Weight_Decay: 1.0e-6
    CFG_Alpha: 0.1  # only using when Use_CFG is true
    OT_Noise_Multiplier: 4  # only using when Use_OT is true
    Accumulated_Gradient_Step: 1 # 25    
    Gradient_Norm: 0.0
    Max_Step: 1000000
    Checkpoint_Save_Interval: 10000
    Logging_Interval: 1
    Evaluation_Interval: 1000
    Inference_Interval: 5000
    Initial_Inference: true
    Inference_in_Train:
        Lyric: [
            ['마','음','울','적','한','날','에','<X>','거','리','를','걸','어','보','고','향','기','로','운','칵','테','일','에','취','해','도','보','고','한','편','의','시','가','있','는','<X>','전','시','회','장','도','가','고','밤','새','도','<X>','록','그','리','움','에','편','질','쓰','고','파',],
            ['떴','다','떴','다','비','행','기','날','아','라','날','아','라','높','이','높','이','날','아','라','우','리','비','행','기',],
            ['만','나','고','<X>','난','외','로','움','을','<X>','알','았','어','내','겐','<X>','관','심','조','<X>','차','<X>','없','<X>','다','는','걸','<X>','알','면','서',],
            ]
        Note: [
            [68,68,68,75,73,72,70,0,72,72,72,73,72,67,67,65,65,65,68,68,66,65,63,65,68,67,68,70,68,68,68,75,73,72,70,0,72,72,72,73,72,67,67,65,65,65,67,68,68,65,63,63,65,68,67,70,68],
            [64,62,60,62,64,64,64,62,62,62,64,67,67,64,62,60,62,64,64,64,62,62,64,62,60],
            [64,66,67,0,59,62,60,59,60,0,59,57,57,59,62,0,67,66,67,0,59,0,62,0,62,60,60,0,59,59,57],
            ]
        Duration: [
            [0.33,0.16,0.33,0.49,0.33,0.16,0.81,0.33,0.16,0.16,0.33,0.16,0.49,0.16,0.82,0.33,0.16,0.33,0.49,0.33,0.16,0.33,0.49,0.33,0.33,0.16,0.33,1.47,0.33,0.16,0.33,0.49,0.33,0.16,0.81,0.33,0.16,0.16,0.33,0.16,0.49,0.16,0.82,0.33,0.16,0.33,0.16,0.33,0.49,0.16,0.33,0.33,0.33,0.33,0.16,0.33,0.82],
            [0.52,0.17,0.35,0.35,0.35,0.35,0.70,0.35,0.35,0.70,0.35,0.35,0.70,0.52,0.17,0.35,0.35,0.35,0.35,0.70,0.35,0.35,0.35,0.35,1.39,],
            [0.53,0.52,0.50,0.57,0.58,0.46,0.48,0.50,0.37,0.13,0.43,0.21,0.57,0.43,0.49,1.44,0.26,0.49,0.14,0.13,0.57,0.26,0.06,0.15,0.63,0.26,0.51,0.20,0.48,0.72,0.22,],
            ]
        Singer: [
            'CSD',
            'CSD',
            'CSD',
            ]
        Language: [
            'Korean',
            'Korean',
            'Korean',
            ]

Inference_Batch_Size: 8
Inference_Path: './results/Inference'
Checkpoint_Path: './results/Checkpoint'
Log_Path: './results/Log'

Weights_and_Biases:
    Use: false
    Project: 'TechSinger_Linear'
    Entity: 'codejin'
    Name: 'Test'
    Save_Checkpoint:
        Use: false
        Interval: 50000 # Unlike local, The capacity of WandB is small.

Use_Mixed_Precision: false
# Use_Multi_GPU: true
# Device: '0,1,2,3,4,5,6,7'
Use_Multi_GPU: false
Device: '0'
