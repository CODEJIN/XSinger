Sound:
    Hop_Size: 256
    N_Mel: 100
    Sample_Rate: 24000
    F0_Min: 65  # C2
    F0_Max: 2094    # C7

Tokens: 124
Notes: 128
Durations: 10000
Genres: 7
Singers: 144
Languages: 4

Encoder:
    Size: 384
    Lyric_Encoder:
        Stack: 4
        Head: 2
        Dropout_Rate: 0.1
        Beta_Distribution_Concentration: 0.2
        FFN:
            Kernel_Size: 7
            Dropout_Rate: 0.1
        Residual_Conv:
            Stack: 2
            Kernel_Size: 5
            Dropout_Rate: 0.1
    Melody_Encoder:
        Stack: 4
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 7
            Dropout_Rate: 0.1
        Residual_Conv:
            Stack: 2
            Kernel_Size: 5
            Dropout_Rate: 0.1
    Phoneme_to_Note_Encoder:
        Stack: 2
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 7
            Dropout_Rate: 0.1
        Residual_Conv:
            Stack: 2
            Kernel_Size: 5
            Dropout_Rate: 0.1
    Cross_Attention:
        Head: 2
        Attention_Prior_Extra_Width_Factor: 2
    Prior_Encoder:
        Stack: 4
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 7
            Dropout_Rate: 0.1
        Residual_Conv:
            Stack: 2
            Kernel_Size: 5
            Dropout_Rate: 0.1

Eliminator:
    Size: 256
    Kernel_Size: 3

Diffusion:
    Size: 512
    Transformer:
        Stack: 6
        Head: 2
        Dropout_Rate: 0.1
        FFN:
            Kernel_Size: 3
            Dropout_Rate: 0.1
        Residual_Conv:
            Stack: 2
            Kernel_Size: 5
            Dropout_Rate: 0.1
    Network_Prediction: 'Flow'   # 'Flow', 'Noise'


Token_Path: '/mnt/f/Datasets/24K.RectifiedFlowSVS.Mel/Token.yaml'
Mel_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowSVS.Mel/Mel_Info.yaml'
F0_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowSVS.Mel/F0_Info.yaml'
Singer_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowSVS.Mel/Singer_Info.yaml'
Genre_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowSVS.Mel/Genre_Info.yaml'
Language_Info_Path: '/mnt/f/Datasets/24K.RectifiedFlowSVS.Mel/Language_Info.yaml'
Train:
    Pattern_Cache: false
    Train_Pattern:
        Path: '/mnt/f/Datasets/24K.RectifiedFlowSVS.Mel/Train'
        Metadata_File: 'METADATA.PICKLE'
        Accumulated_Dataset_Epoch: 1000 # This is to prevent slow down from torch.utils.data.DataLoader when the number of patterns is small.
        Augmentation_Ratio: 0.10
    Eval_Pattern:
        Path: '/mnt/f/Datasets/24K.RectifiedFlowSVS.Mel/Eval'
        Metadata_File: 'METADATA.PICKLE'
        Accumulated_Dataset_Epoch: 32   # When singer is 1, evaluation pattern is also 1. Because offset is selected randomly, this is meaningful.
    Num_Workers: 2
    Batch_Size: 32
    Pattern_Length:
        Min: 384
        Max: 768
    Guided_Attention_Sigma: 0.35
    Num_Combination: 3
    Learning_Rate:
        Initial: 1.0e-4
        Decay: 0.999875
        Decay_Epoch: 1000
        Lambda:
            Cross_Attention: 10.0
    ADAM:
        Beta1: 0.9
        Beta2: 0.999
        Epsilon: 1.0e-7
    Weight_Decay: 1.0e-6
    Accumulated_Gradient_Step: 1 # 25    
    Gradient_Norm: 1.0
    Max_Step: 1000000
    Checkpoint_Save_Interval: 10000
    Logging_Interval: 1
    Evaluation_Interval: 1000
    Inference_Interval: 5000
    Initial_Inference: true
    Inference_in_Train:
        Lyric: [
            ['마','음','울','적','한','날','에','<X>','거','리','를','걸','어','보','고','향','기','로','운','칵','테','일','에','취','해','도','보','고','한','편','의','시','가','있','는','<X>','전','시','회','장','도','가','고','밤','새','도','<X>','록','그','리','움','에','편','질','쓰','고','파',],
            ['떴','다','떴','다','비','행','기','날','아','라','날','아','라','높','이','높','이','날','아','라','우','리','비','행','기',],
            ['만','나','고','<X>','난','외','로','움','을','<X>','알','았','어','내','겐','<X>','관','심','조','<X>','차','<X>','없','<X>','다','는','걸','<X>','알','면','서',],
            ]
        Note: [
            [68,68,68,75,73,72,70,0,72,72,72,73,72,67,67,65,65,65,68,68,66,65,63,65,68,67,68,70,68,68,68,75,73,72,70,0,72,72,72,73,72,67,67,65,65,65,67,68,68,65,63,63,65,68,67,70,68],
            [64,62,60,62,64,64,64,62,62,62,64,67,67,64,62,60,62,64,64,64,62,62,64,62,60],
            [64,66,67,0,59,62,60,59,60,0,59,57,57,59,62,0,67,66,67,0,59,0,62,0,62,60,60,0,59,59,57],
            ]
        Duration: [
            [0.33,0.16,0.33,0.49,0.33,0.16,0.81,0.33,0.16,0.16,0.33,0.16,0.49,0.16,0.82,0.33,0.16,0.33,0.49,0.33,0.16,0.33,0.49,0.33,0.33,0.16,0.33,1.47,0.33,0.16,0.33,0.49,0.33,0.16,0.81,0.33,0.16,0.16,0.33,0.16,0.49,0.16,0.82,0.33,0.16,0.33,0.16,0.33,0.49,0.16,0.33,0.33,0.33,0.33,0.16,0.33,0.82],
            [0.52,0.17,0.35,0.35,0.35,0.35,0.70,0.35,0.35,0.70,0.35,0.35,0.70,0.52,0.17,0.35,0.35,0.35,0.35,0.70,0.35,0.35,0.35,0.35,1.39,],
            [0.53,0.52,0.50,0.57,0.58,0.46,0.48,0.50,0.37,0.13,0.43,0.21,0.57,0.43,0.49,1.44,0.26,0.49,0.14,0.13,0.57,0.26,0.06,0.15,0.63,0.26,0.51,0.20,0.48,0.72,0.22,],
            ]
        Singer: [
            'CSD',
            'CSD',
            'CSD',
            ]
        Language: [
            'Korean',
            'Korean',
            'Korean',
            ]

Inference_Batch_Size: 8
Inference_Path: './results/Inference'
Checkpoint_Path: './results/Checkpoint'
Log_Path: './results/Log'

Weights_and_Biases:
    Use: false
    Project: 'RectifiedFlowSVS'
    Entity: 'codejin'
    Name: 'Test'
    Save_Checkpoint:
        Use: false
        Interval: 50000 # Unlike local, The capacity of WandB is small.

Use_Mixed_Precision: true
# Use_Multi_GPU: true
# Device: '0,1,2,3,4,5,6,7'
Use_Multi_GPU: false
Device: '0'
